{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-09-21T17:43:00.101087Z",
     "start_time": "2025-09-21T17:42:50.471356Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import scipy.sparse\n",
    "import json\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Mostra diret√≥rio e arquivos dispon√≠veis\n",
    "print(\"Diret√≥rio atual:\", os.getcwd())\n",
    "print(\"Arquivos na pasta datasets:\", os.listdir(\"../datasets\"))\n",
    "\n",
    "# Leitura do CSV\n",
    "try:\n",
    "    df = pd.read_csv(\"../datasets/phishing.csv\", encoding=\"utf-8\")\n",
    "except UnicodeDecodeError:\n",
    "    df = pd.read_csv(\"../datasets/phishing.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "# Limpeza b√°sica do texto\n",
    "corpus = df['Email Text'].astype(str).apply(\n",
    "    lambda x: re.sub(r'[^a-zA-Z0-9√°√©√≠√≥√∫√£√µ√¢√™√¥√ß√Å√â√ç√ì√ö√É√ï√Ç√ä√î√á\\s]', '', x.lower())\n",
    ")\n",
    "\n",
    "# =====================================================\n",
    "# üîπ Bag of Words com CountVectorizer\n",
    "# =====================================================\n",
    "count_vectorizer = CountVectorizer(\n",
    "    lowercase=True,\n",
    "    stop_words=None,     # pode trocar por 'english' ou lista em portugu√™s\n",
    "    max_features=5000,   # limita vocabul√°rio\n",
    "    min_df=5,            # ignora palavras raras\n",
    "    max_df=0.8           # ignora palavras muito comuns\n",
    ")\n",
    "\n",
    "X_count = count_vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(\"Formato CountVectorizer:\", X_count.shape)\n",
    "\n",
    "# Salva matriz esparsa\n",
    "scipy.sparse.save_npz(\"../datasets/phishing_bow_count.npz\", X_count)\n",
    "\n",
    "# Salva vocabul√°rio\n",
    "with open(\"../datasets/phishing_bow_vocab.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(count_vectorizer.get_feature_names_out().tolist(), f, ensure_ascii=False, indent=2)\n",
    "\n",
    "# =====================================================\n",
    "# üîπ TF-IDF\n",
    "# =====================================================\n",
    "tfidf_vectorizer = TfidfVectorizer(\n",
    "    lowercase=True,\n",
    "    stop_words=None,\n",
    "    max_features=5000,\n",
    "    min_df=5,\n",
    "    max_df=0.8\n",
    ")\n",
    "\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
    "\n",
    "print(\"Formato TF-IDF:\", X_tfidf.shape)\n",
    "\n",
    "# Salva matriz esparsa\n",
    "scipy.sparse.save_npz(\"../datasets/phishing_tfidf.npz\", X_tfidf)\n",
    "\n",
    "# Salva vocabul√°rio\n",
    "with open(\"../datasets/phishing_tfidf_vocab.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(tfidf_vectorizer.get_feature_names_out().tolist(), f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"‚úÖ Bag of Words e TF-IDF gerados e salvos com sucesso!\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diret√≥rio atual: C:\\Users\\Bruno\\OneDrive\\TCC\\PythonProject\\1.Transformacao_Dataset\n",
      "Arquivos na pasta datasets: ['DDoS.csv', 'phishing.csv', 'phishing_transformed.csv', 'ransomware.csv']\n",
      "Formato CountVectorizer: (18650, 5000)\n",
      "Formato TF-IDF: (18650, 5000)\n",
      "‚úÖ Bag of Words e TF-IDF gerados e salvos com sucesso!\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-21T17:43:13.415130Z",
     "start_time": "2025-09-21T17:43:13.286307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import scipy.sparse\n",
    "import json\n",
    "\n",
    "# Carregar BoW\n",
    "X_count = scipy.sparse.load_npz(\"../datasets/phishing_bow_count.npz\")\n",
    "\n",
    "with open(\"../datasets/phishing_bow_vocab.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    vocab_bow = json.load(f)\n",
    "\n",
    "# Carregar TF-IDF\n",
    "X_tfidf = scipy.sparse.load_npz(\"../datasets/phishing_tfidf.npz\")\n",
    "\n",
    "with open(\"../datasets/phishing_tfidf_vocab.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    vocab_tfidf = json.load(f)\n",
    "\n",
    "print(\"BoW:\", X_count.shape)\n",
    "print(\"TF-IDF:\", X_tfidf.shape)\n"
   ],
   "id": "27d84e058583772d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BoW: (18650, 5000)\n",
      "TF-IDF: (18650, 5000)\n"
     ]
    }
   ],
   "execution_count": 2
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
